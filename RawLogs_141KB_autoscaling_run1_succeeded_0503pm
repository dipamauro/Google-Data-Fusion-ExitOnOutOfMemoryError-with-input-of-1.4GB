2023-03-19 22:52:52,861 - DEBUG [provisioning-task-9:i.c.c.i.p.t.ProvisioningTask@126] - Executing PROVISION subtask REQUESTING_CREATE for program run program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf.
2023-03-19 22:52:52,919 - DEBUG [provisioning-task-9:i.c.c.r.s.p.d.DataprocProvisioner@250] - Not checking cluster reuse, enabled: true, skip delete: false, idle ttl: 240, reuse threshold: 15
2023-03-19 22:52:53,032 - INFO  [provisioning-task-9:i.c.c.r.s.p.d.DataprocProvisioner@203] - Creating Dataproc cluster cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf in project smooth-keel-381016, in region us-west1, with image 2.0, with labels {goog-datafusion-version=6_8, cdap-version=6_8_1-1677149596172, goog-datafusion-edition=basic}, endpoint dataproc.googleapis.com:443
2023-03-19 22:52:55,294 - WARN  [provisioning-task-9:i.c.c.r.s.p.d.DataprocProvisioner@211] - Encountered 2 warnings while creating Dataproc cluster:
Failed to validate permissions required for custom service account: '738979054940-compute@developer.gserviceaccount.com'. Cluster creation could still be successful if required permissions have been granted to the respective service accounts as mentioned in the document https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/service-accounts#dataproc_service_accounts_2. This could be due to Cloud Resource Manager API hasn't been enabled in your project '738979054940' before or it is disabled. Enable it by visiting 'https://console.developers.google.com/apis/api/cloudresourcemanager.googleapis.com/overview?project=738979054940'.
For PD-Standard without local SSDs, we strongly recommend provisioning 1TB or larger to ensure consistently high I/O performance. See https://cloud.google.com/compute/docs/disks/performance for information on disk I/O performance.
2023-03-19 22:52:55,296 - DEBUG [provisioning-task-9:i.c.c.i.p.t.ProvisioningTask@130] - Completed PROVISION subtask REQUESTING_CREATE for program run program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf.
2023-03-19 22:54:03,425 - DEBUG [provisioning-task-9:i.c.c.i.p.t.ProvisioningTask@126] - Executing PROVISION subtask POLLING_CREATE for program run program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf.
2023-03-19 22:54:03,570 - DEBUG [provisioning-task-9:i.c.c.i.p.t.ProvisioningTask@130] - Completed PROVISION subtask POLLING_CREATE for program run program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf.
2023-03-19 22:54:34,880 - DEBUG [provisioning-task-9:i.c.c.i.p.t.ProvisioningTask@126] - Executing PROVISION subtask POLLING_CREATE for program run program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf.
2023-03-19 22:54:34,980 - DEBUG [provisioning-task-9:i.c.c.i.p.t.ProvisioningTask@130] - Completed PROVISION subtask POLLING_CREATE for program run program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf.
2023-03-19 22:55:04,315 - DEBUG [provisioning-task-6:i.c.c.i.p.t.ProvisioningTask@117] - Completed PROVISION task for program run program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf.
2023-03-19 22:55:07,592 - INFO  [program-start-3:i.c.c.i.a.r.d.DistributedProgramRunner@591] - Starting Workflow Program 'DataPipelineWorkflow' with Arguments [logical.start.time=1679266370962, system.profile.name=SYSTEM:autoscaling-dataproc], with debugging false
2023-03-19 22:55:07,642 - DEBUG [runtime-scheduler-9:i.c.c.i.a.r.d.r.AbstractRuntimeTwillPreparer@521] - Create and copy application.jar
2023-03-19 22:55:07,643 - DEBUG [runtime-scheduler-9:i.c.c.i.a.r.d.r.AbstractRuntimeTwillPreparer@529] - Done application.jar
2023-03-19 22:55:07,644 - DEBUG [runtime-scheduler-9:i.c.c.i.a.r.d.r.AbstractRuntimeTwillPreparer@542] - Create and copy resources.jar
2023-03-19 22:55:07,683 - DEBUG [runtime-scheduler-9:i.c.c.i.a.r.d.r.AbstractRuntimeTwillPreparer@545] - Done resources.jar
2023-03-19 22:55:07,684 - DEBUG [runtime-scheduler-9:i.c.c.i.a.r.d.r.AbstractRuntimeTwillPreparer@585] - Populating Runnable LocalFiles
2023-03-19 22:55:07,684 - DEBUG [runtime-scheduler-9:i.c.c.i.a.r.d.r.AbstractRuntimeTwillPreparer@592] - Added file file:/data/tmp/1679266505303-0/cConf.xml
2023-03-19 22:55:07,684 - DEBUG [runtime-scheduler-9:i.c.c.i.a.r.d.r.AbstractRuntimeTwillPreparer@592] - Added file file:/data/tmp/1679266505303-0/logback.xml
2023-03-19 22:55:07,684 - DEBUG [runtime-scheduler-9:i.c.c.i.a.r.d.r.AbstractRuntimeTwillPreparer@592] - Added file file:/data/tmp/1679266505303-0/1679266505349-0/artifacts.jar
2023-03-19 22:55:07,684 - DEBUG [runtime-scheduler-9:i.c.c.i.a.r.d.r.AbstractRuntimeTwillPreparer@592] - Added file file:/data/tmp/1679266505303-0/appSpec6327110313136459712.json
2023-03-19 22:55:07,684 - DEBUG [runtime-scheduler-9:i.c.c.i.a.r.d.r.AbstractRuntimeTwillPreparer@592] - Added file file:/data/tmp/workflow.default.xml-to-json-141KB.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf/program.jar
2023-03-19 22:55:07,684 - DEBUG [runtime-scheduler-9:i.c.c.i.a.r.d.r.AbstractRuntimeTwillPreparer@592] - Added file file:/data/tmp/1679266505303-0/1679266505349-0/artifacts.jar
2023-03-19 22:55:07,684 - DEBUG [runtime-scheduler-9:i.c.c.i.a.r.d.r.AbstractRuntimeTwillPreparer@592] - Added file file:/data/tmp/1679266505303-0/hConf.xml
2023-03-19 22:55:07,685 - DEBUG [runtime-scheduler-9:i.c.c.i.a.r.d.r.AbstractRuntimeTwillPreparer@592] - Added file file:/data/tmp/1679266505303-0/program.options.json
2023-03-19 22:55:07,685 - DEBUG [runtime-scheduler-9:i.c.c.i.a.r.d.r.AbstractRuntimeTwillPreparer@595] - Done Runnable LocalFiles
2023-03-19 22:55:07,685 - DEBUG [runtime-scheduler-9:i.c.c.i.a.r.d.r.AbstractRuntimeTwillPreparer@613] - Creating /data/tmp/c6bfd724-c6a8-11ed-8be4-3e40d30925cf9089339769983442602/runtime.config.jar6933610284193839632/twillSpec.json
2023-03-19 22:55:07,687 - DEBUG [runtime-scheduler-9:i.c.c.i.a.r.d.r.AbstractRuntimeTwillPreparer@633] - Done /data/tmp/c6bfd724-c6a8-11ed-8be4-3e40d30925cf9089339769983442602/runtime.config.jar6933610284193839632/twillSpec.json
2023-03-19 22:55:07,687 - DEBUG [runtime-scheduler-9:i.c.c.i.a.r.d.r.AbstractRuntimeTwillPreparer@644] - Creating /data/tmp/c6bfd724-c6a8-11ed-8be4-3e40d30925cf9089339769983442602/runtime.config.jar6933610284193839632/logback-template.xml
2023-03-19 22:55:07,688 - DEBUG [runtime-scheduler-9:i.c.c.i.a.r.d.r.AbstractRuntimeTwillPreparer@648] - Done /data/tmp/c6bfd724-c6a8-11ed-8be4-3e40d30925cf9089339769983442602/runtime.config.jar6933610284193839632/logback-template.xml
2023-03-19 22:55:07,688 - DEBUG [runtime-scheduler-9:i.c.c.i.a.r.d.r.AbstractRuntimeTwillPreparer@550] - Create and copy runtime.config.jar
2023-03-19 22:55:07,690 - DEBUG [runtime-scheduler-9:i.c.c.i.a.r.d.r.AbstractRuntimeTwillPreparer@572] - Done runtime.config.jar
2023-03-19 22:55:07,748 - INFO  [runtime-scheduler-9:i.c.c.i.a.r.d.r.RuntimeJobTwillPreparer@107] - JVM properties {logback.configurationFile=logback.xml, CDAP_LOG_DIR=<LOG_DIR>, twill.container.class.loader=io.cdap.cdap.common.app.MainClassLoader}
2023-03-19 22:55:07,748 - INFO  [runtime-scheduler-9:i.c.c.i.a.r.d.r.RuntimeJobTwillPreparer@97] - Starting runnable DataPipelineWorkflow for runId program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf with job manager.
2023-03-19 22:55:07,748 - DEBUG [runtime-scheduler-9:i.c.c.r.s.r.DataprocRuntimeJobManager@242] - Launching run c6bfd724-c6a8-11ed-8be4-3e40d30925cf with following configurations: cluster cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf, project smooth-keel-381016, region us-west1, bucket df-2146571977277703915-y7xm3h6gtui63iiraizbbqaaaa.
2023-03-19 22:55:07,794 - DEBUG [provisioning-context-17:i.c.c.r.s.r.DataprocRuntimeJobManager@550] - Uploading a file of size 88847 bytes from file:/data/tmp/1679266505303-0/cConf.xml to gs://df-2146571977277703915-y7xm3h6gtui63iiraizbbqaaaa/cdap-job/c6bfd724-c6a8-11ed-8be4-3e40d30925cf/cConf.xml of region bucket type located at US-WEST1
2023-03-19 22:55:07,794 - DEBUG [provisioning-context-18:i.c.c.r.s.r.DataprocRuntimeJobManager@550] - Uploading a file of size 33542 bytes from file:/data/tmp/c6bfd724-c6a8-11ed-8be4-3e40d30925cf9089339769983442602/resources.jar to gs://df-2146571977277703915-y7xm3h6gtui63iiraizbbqaaaa/cdap-job/c6bfd724-c6a8-11ed-8be4-3e40d30925cf/resources.jar of region bucket type located at US-WEST1
2023-03-19 22:55:07,803 - DEBUG [provisioning-context-15:i.c.c.r.s.r.DataprocRuntimeJobManager@550] - Uploading a file of size 172146 bytes from file:/data/tmp/1679266505303-0/hConf.xml to gs://df-2146571977277703915-y7xm3h6gtui63iiraizbbqaaaa/cdap-job/c6bfd724-c6a8-11ed-8be4-3e40d30925cf/hConf.xml of region bucket type located at US-WEST1
2023-03-19 22:55:07,803 - DEBUG [provisioning-context-16:i.c.c.r.s.r.DataprocRuntimeJobManager@550] - Uploading a file of size 102757 bytes from file:/data/tmp/1679266505303-0/appSpec6327110313136459712.json to gs://df-2146571977277703915-y7xm3h6gtui63iiraizbbqaaaa/cdap-job/c6bfd724-c6a8-11ed-8be4-3e40d30925cf/appSpec.json of region bucket type located at US-WEST1
2023-03-19 22:55:07,823 - DEBUG [provisioning-context-12:i.c.c.r.s.r.DataprocRuntimeJobManager@511] - Skip uploading file file:/data/tmp/runner.cache3393733544389291804/65206652e8550d44362557de0bb879a6-application.jar to gs://df-2146571977277703915-y7xm3h6gtui63iiraizbbqaaaa/cdap-job/cached-artifacts/6.8.1/application.jar because it exists.
2023-03-19 22:55:07,823 - DEBUG [provisioning-context-14:i.c.c.r.s.r.DataprocRuntimeJobManager@511] - Skip uploading file file:/tmp/dataproc.launcher.cache/twill.jar to gs://df-2146571977277703915-y7xm3h6gtui63iiraizbbqaaaa/cdap-job/cached-artifacts/6.8.1/twill.jar because it exists.
2023-03-19 22:55:07,826 - DEBUG [provisioning-context-19:i.c.c.r.s.r.DataprocRuntimeJobManager@511] - Skip uploading file file:/tmp/dataproc.launcher.cache/launcher.jar to gs://df-2146571977277703915-y7xm3h6gtui63iiraizbbqaaaa/cdap-job/cached-artifacts/6.8.1/launcher.jar because it exists.
2023-03-19 22:55:07,828 - DEBUG [provisioning-context-11:i.c.c.r.s.r.DataprocRuntimeJobManager@511] - Skip uploading file file:/data/tmp/1679266505303-0/1679266505349-0/artifacts.jar to gs://df-2146571977277703915-y7xm3h6gtui63iiraizbbqaaaa/cdap-job/cached-artifacts/artifacts_e05a6033858b1b079c55b0c5376f924050a2a6810509f537e0c3236936afdf75_1680652800000 because it exists.
2023-03-19 22:55:07,831 - DEBUG [provisioning-context-13:i.c.c.r.s.r.DataprocRuntimeJobManager@511] - Skip uploading file file:/data/tmp/workflow.default.xml-to-json-141KB.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf/program.jar to gs://df-2146571977277703915-y7xm3h6gtui63iiraizbbqaaaa/cdap-job/cached-artifacts/program_366688bda18303296fc427af534a192eb32fd810718b7d9d11c6eab7ef1ca947_1678579200000.jar because it exists.
2023-03-19 22:55:07,832 - DEBUG [provisioning-context-10:i.c.c.r.s.r.DataprocRuntimeJobManager@511] - Skip uploading file file:/data/tmp/1679266505303-0/1679266505349-0/artifacts.jar to gs://df-2146571977277703915-y7xm3h6gtui63iiraizbbqaaaa/cdap-job/cached-artifacts/artifacts_archive_e05a6033858b1b079c55b0c5376f924050a2a6810509f537e0c3236936afdf75_1680652800000.jar because it exists.
2023-03-19 22:55:07,850 - DEBUG [provisioning-context-14:i.c.c.r.s.r.DataprocRuntimeJobManager@550] - Uploading a file of size 3236 bytes from file:/data/tmp/1679266505303-0/program.options.json to gs://df-2146571977277703915-y7xm3h6gtui63iiraizbbqaaaa/cdap-job/c6bfd724-c6a8-11ed-8be4-3e40d30925cf/program.options.json of region bucket type located at US-WEST1
2023-03-19 22:55:07,852 - DEBUG [provisioning-context-19:i.c.c.r.s.r.DataprocRuntimeJobManager@550] - Uploading a file of size 2735 bytes from file:/data/tmp/c6bfd724-c6a8-11ed-8be4-3e40d30925cf9089339769983442602/runtime.config.jar7647018503277994933.tmp to gs://df-2146571977277703915-y7xm3h6gtui63iiraizbbqaaaa/cdap-job/c6bfd724-c6a8-11ed-8be4-3e40d30925cf/runtime.config.jar of region bucket type located at US-WEST1
2023-03-19 22:55:07,861 - DEBUG [provisioning-context-12:i.c.c.r.s.r.DataprocRuntimeJobManager@550] - Uploading a file of size 4013 bytes from file:/data/tmp/1679266505303-0/logback.xml to gs://df-2146571977277703915-y7xm3h6gtui63iiraizbbqaaaa/cdap-job/c6bfd724-c6a8-11ed-8be4-3e40d30925cf/logback.xml of region bucket type located at US-WEST1
2023-03-19 22:55:07,898 - DEBUG [provisioning-context-16:i.c.c.r.s.r.DataprocRuntimeJobManager@593] - Successfully uploaded file file:/data/tmp/1679266505303-0/appSpec6327110313136459712.json to gs://gs://df-2146571977277703915-y7xm3h6gtui63iiraizbbqaaaa/cdap-job/c6bfd724-c6a8-11ed-8be4-3e40d30925cf/appSpec.json in 94 ms.
2023-03-19 22:55:07,905 - DEBUG [provisioning-context-18:i.c.c.r.s.r.DataprocRuntimeJobManager@593] - Successfully uploaded file file:/data/tmp/c6bfd724-c6a8-11ed-8be4-3e40d30925cf9089339769983442602/resources.jar to gs://gs://df-2146571977277703915-y7xm3h6gtui63iiraizbbqaaaa/cdap-job/c6bfd724-c6a8-11ed-8be4-3e40d30925cf/resources.jar in 111 ms.
2023-03-19 22:55:07,919 - DEBUG [provisioning-context-17:i.c.c.r.s.r.DataprocRuntimeJobManager@593] - Successfully uploaded file file:/data/tmp/1679266505303-0/cConf.xml to gs://gs://df-2146571977277703915-y7xm3h6gtui63iiraizbbqaaaa/cdap-job/c6bfd724-c6a8-11ed-8be4-3e40d30925cf/cConf.xml in 125 ms.
2023-03-19 22:55:07,923 - DEBUG [provisioning-context-15:i.c.c.r.s.r.DataprocRuntimeJobManager@593] - Successfully uploaded file file:/data/tmp/1679266505303-0/hConf.xml to gs://gs://df-2146571977277703915-y7xm3h6gtui63iiraizbbqaaaa/cdap-job/c6bfd724-c6a8-11ed-8be4-3e40d30925cf/hConf.xml in 119 ms.
2023-03-19 22:55:07,961 - DEBUG [provisioning-context-14:i.c.c.r.s.r.DataprocRuntimeJobManager@593] - Successfully uploaded file file:/data/tmp/1679266505303-0/program.options.json to gs://gs://df-2146571977277703915-y7xm3h6gtui63iiraizbbqaaaa/cdap-job/c6bfd724-c6a8-11ed-8be4-3e40d30925cf/program.options.json in 110 ms.
2023-03-19 22:55:07,966 - DEBUG [provisioning-context-12:i.c.c.r.s.r.DataprocRuntimeJobManager@593] - Successfully uploaded file file:/data/tmp/1679266505303-0/logback.xml to gs://gs://df-2146571977277703915-y7xm3h6gtui63iiraizbbqaaaa/cdap-job/c6bfd724-c6a8-11ed-8be4-3e40d30925cf/logback.xml in 104 ms.
2023-03-19 22:55:07,978 - DEBUG [provisioning-context-19:i.c.c.r.s.r.DataprocRuntimeJobManager@593] - Successfully uploaded file file:/data/tmp/c6bfd724-c6a8-11ed-8be4-3e40d30925cf9089339769983442602/runtime.config.jar7647018503277994933.tmp to gs://gs://df-2146571977277703915-y7xm3h6gtui63iiraizbbqaaaa/cdap-job/c6bfd724-c6a8-11ed-8be4-3e40d30925cf/runtime.config.jar in 125 ms.
2023-03-19 22:55:08,140 - DEBUG [runtime-scheduler-9:i.c.c.r.s.r.DataprocRuntimeJobManager@313] - Successfully submitted hadoop job default_xml-to-json-141KB_DataPipelineWorkflow_c6bfd724-c6a8-11ed-8be4-3e40d30925cf to cluster cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf.
2023-03-19 22:55:08,141 - DEBUG [runtime-scheduler-9:i.c.c.i.a.r.d.r.RemoteExecutionTwillRunnerService@607] - Startup task completed for program run program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf
2023-03-19 22:55:35,346 - DEBUG [main:i.c.c.i.a.r.m.RuntimeMonitors@119] - Setting runtime service routing base URI to https://r-xml-to-json-smooth-keel-381016-dot-usw1.datafusion.googleusercontent.com/v3Internal/runtime/namespaces/default/apps/xml-to-json-141KB/versions/-SNAPSHOT/workflows/DataPipelineWorkflow/runs/c6bfd724-c6a8-11ed-8be4-3e40d30925cf/services/
2023-03-19 22:55:36,362 - INFO  [TMSLogPublisher:i.c.c.m.s.l.LevelDBTableFactory@173] - Messaging metadata table created at data/messaging/namespace:system.tms.meta
2023-03-19 22:55:37,654 - DEBUG [main:i.c.c.i.a.r.d.r.DefaultRuntimeJob@566] - Starting core service LogAppenderLoaderService [NEW]
2023-03-19 22:55:37,656 - DEBUG [main:i.c.c.i.a.r.d.r.DefaultRuntimeJob@566] - Starting core service CoreMessagingService [NEW]
2023-03-19 22:55:37,673 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.audit
2023-03-19 22:55:37,677 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.metadata
2023-03-19 22:55:37,678 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.dataevent
2023-03-19 22:55:37,679 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.metrics0
2023-03-19 22:55:37,680 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.metrics1
2023-03-19 22:55:37,681 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.metrics2
2023-03-19 22:55:37,686 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.metrics3
2023-03-19 22:55:37,687 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.metrics4
2023-03-19 22:55:37,688 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.metrics5
2023-03-19 22:55:37,691 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.metrics6
2023-03-19 22:55:37,692 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.metrics7
2023-03-19 22:55:37,693 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.metrics8
2023-03-19 22:55:37,695 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.metrics9
2023-03-19 22:55:37,696 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.metricsadmin
2023-03-19 22:55:37,697 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.timeevent
2023-03-19 22:55:37,699 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.programstatusevent
2023-03-19 22:55:37,700 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.programstatusevent0
2023-03-19 22:55:37,701 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.programstatusrecordevent
2023-03-19 22:55:37,702 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.logs0
2023-03-19 22:55:37,703 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.logs1
2023-03-19 22:55:37,705 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.logs2
2023-03-19 22:55:37,706 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.logs3
2023-03-19 22:55:37,707 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.logs4
2023-03-19 22:55:37,709 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.logs5
2023-03-19 22:55:37,710 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.logs6
2023-03-19 22:55:37,712 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.logs7
2023-03-19 22:55:37,713 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.logs8
2023-03-19 22:55:37,717 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.logs9
2023-03-19 22:55:37,718 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.preview
2023-03-19 22:55:37,719 - DEBUG [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@306] - System topic created: topic:system.previewlog0
2023-03-19 22:55:37,720 - INFO  [CoreMessagingService STARTING:i.c.c.m.s.CoreMessagingService@234] - Core Messaging Service started
2023-03-19 22:55:37,720 - DEBUG [main:i.c.c.i.a.r.d.r.DefaultRuntimeJob@566] - Starting core service MessagingHttpService [NEW]
2023-03-19 22:55:37,721 - INFO  [MessagingHttpService STARTING:i.c.h.NettyHttpService@181] - Starting HTTP Service messaging.service at address cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m.us-west1-b.c.smooth-keel-381016.internal/10.138.0.38:0
2023-03-19 22:55:37,910 - DEBUG [MessagingHttpService STARTING:i.c.c.i.a.r.d.r.RemoteExecutionDiscoveryService@76] - Discoverable messaging.service with address cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m.us-west1-b.c.smooth-keel-381016.internal/10.138.0.38:46683 added to configuration with payload https://
2023-03-19 22:55:37,913 - DEBUG [MessagingHttpService STARTING:i.c.c.i.a.r.d.r.RemoteExecutionDiscoveryService@142] - Update discoverable messaging.service with address cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m.us-west1-b.c.smooth-keel-381016.internal/10.138.0.38:46683 and payload https://
2023-03-19 22:55:37,916 - INFO  [MessagingHttpService STARTING:i.c.c.m.s.MessagingHttpService@107] - Messaging HTTP server started on cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m.us-west1-b.c.smooth-keel-381016.internal/10.138.0.38:46683
2023-03-19 22:55:37,919 - DEBUG [main:i.c.c.i.a.r.d.r.DefaultRuntimeJob@566] - Starting core service MessagingMetricsCollectionService [NEW]
2023-03-19 22:55:37,920 - DEBUG [main:i.c.c.i.a.r.d.r.DefaultRuntimeJob@566] - Starting core service RuntimeClientService [NEW]
2023-03-19 22:55:37,921 - DEBUG [RuntimeClientService:i.c.c.c.s.AbstractRetryableScheduledService@99] - Starting scheduled service RuntimeClientService
2023-03-19 22:55:37,923 - DEBUG [main:i.c.c.i.a.r.d.r.DefaultRuntimeJob@566] - Starting core service ProfileMetricService [NEW]
2023-03-19 22:55:38,195 - DEBUG [main:i.c.c.a.r.s.SparkProgramRuntimeProvider@169] - using sparkCompat SPARK3_2_12
2023-03-19 22:55:38,306 - DEBUG [main:i.c.c.a.r.s.SparkPackageUtils@317] - Located Spark library in in /usr/lib/spark/jars
2023-03-19 22:55:40,017 - DEBUG [RuntimeClientService:i.c.c.i.a.r.d.r.RemoteExecutionDiscoveryService@142] - Update discoverable runtime with address r-xml-to-json-smooth-keel-381016-dot-usw1.datafusion.googleusercontent.com/74.125.135.132:443 and payload https://
2023-03-19 22:55:41,125 - DEBUG [main:i.c.c.i.a.r.d.r.RemoteExecutionDiscoveryService@142] - Update discoverable svc.system.pipeline.studio with address svc.system.pipeline.studio:0 and payload https://
2023-03-19 22:55:47,290 - DEBUG [main:i.c.c.a.r.s.SparkProgramRuntimeProvider@169] - using sparkCompat SPARK3_2_12
2023-03-19 22:55:47,499 - WARN  [main:i.c.c.c.c.Configuration@1814] - file:/tmp/default_xml-to-json-141KB_DataPipelineWorkflow_c6bfd724-c6a8-11ed-8be4-3e40d30925cf/cConf.xml:an attempt to override final parameter: support.bundle.max.instances;  Ignoring.
2023-03-19 22:55:47,501 - WARN  [main:i.c.c.c.c.Configuration@1814] - file:/tmp/default_xml-to-json-141KB_DataPipelineWorkflow_c6bfd724-c6a8-11ed-8be4-3e40d30925cf/cConf.xml:an attempt to override final parameter: messaging.system.topics;  Ignoring.
2023-03-19 22:55:47,503 - WARN  [main:i.c.c.c.c.Configuration@1814] - file:/tmp/default_xml-to-json-141KB_DataPipelineWorkflow_c6bfd724-c6a8-11ed-8be4-3e40d30925cf/cConf.xml:an attempt to override final parameter: messaging.max.instances;  Ignoring.
2023-03-19 22:55:47,506 - WARN  [main:i.c.c.c.c.Configuration@1814] - file:/tmp/default_xml-to-json-141KB_DataPipelineWorkflow_c6bfd724-c6a8-11ed-8be4-3e40d30925cf/cConf.xml:an attempt to override final parameter: app.program.runtime.monitor.server.info.file;  Ignoring.
2023-03-19 22:55:47,523 - DEBUG [main:i.c.c.a.r.s.SparkProgramRuntimeProvider@169] - using sparkCompat SPARK3_2_12
2023-03-19 22:55:49,454 - DEBUG [main:i.c.c.a.r.s.SparkPackageUtils@317] - Located Spark library in in /usr/lib/spark/jars
2023-03-19 22:55:58,116 - DEBUG [main:i.c.c.a.r.s.SparkPackageUtils@259] - Adding files from /etc/hadoop/conf to __spark_conf__.zip
2023-03-19 22:55:58,380 - DEBUG [main:i.c.c.i.a.r.d.ProgramTwillApplication@127] - Localizing file for program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf: pyspark.zip LocalizeResource{archive=false, uri=file:/usr/lib/spark/python/lib/pyspark.zip}
2023-03-19 22:55:58,386 - DEBUG [main:i.c.c.i.a.r.d.ProgramTwillApplication@127] - Localizing file for program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf: logback.xml LocalizeResource{archive=false, uri=file:/tmp/default_xml-to-json-141KB_DataPipelineWorkflow_c6bfd724-c6a8-11ed-8be4-3e40d30925cf/data/tmp/1679266547507-0/logback.xml}
2023-03-19 22:55:58,386 - DEBUG [main:i.c.c.i.a.r.d.ProgramTwillApplication@127] - Localizing file for program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf: __spark_conf__ LocalizeResource{archive=true, uri=file:/tmp/default_xml-to-json-141KB_DataPipelineWorkflow_c6bfd724-c6a8-11ed-8be4-3e40d30925cf/data/tmp/1679266547507-0/__spark_conf__6564675408104817780.zip}
2023-03-19 22:55:58,388 - DEBUG [main:i.c.c.i.a.r.d.ProgramTwillApplication@127] - Localizing file for program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf: appSpec.json LocalizeResource{archive=false, uri=file:/tmp/default_xml-to-json-141KB_DataPipelineWorkflow_c6bfd724-c6a8-11ed-8be4-3e40d30925cf/data/tmp/1679266547507-0/appSpec2642055089120395125.json}
2023-03-19 22:55:58,389 - DEBUG [main:i.c.c.i.a.r.d.ProgramTwillApplication@127] - Localizing file for program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf: hConf.xml LocalizeResource{archive=false, uri=file:/tmp/default_xml-to-json-141KB_DataPipelineWorkflow_c6bfd724-c6a8-11ed-8be4-3e40d30925cf/data/tmp/1679266547507-0/hConf.xml}
2023-03-19 22:55:58,390 - DEBUG [main:i.c.c.i.a.r.d.ProgramTwillApplication@127] - Localizing file for program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf: program.options.json LocalizeResource{archive=false, uri=file:/tmp/default_xml-to-json-141KB_DataPipelineWorkflow_c6bfd724-c6a8-11ed-8be4-3e40d30925cf/data/tmp/1679266547507-0/program.options.json}
2023-03-19 22:55:58,391 - DEBUG [main:i.c.c.i.a.r.d.ProgramTwillApplication@127] - Localizing file for program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf: cConf.xml LocalizeResource{archive=false, uri=file:/tmp/default_xml-to-json-141KB_DataPipelineWorkflow_c6bfd724-c6a8-11ed-8be4-3e40d30925cf/data/tmp/1679266547507-0/cConf.xml}
2023-03-19 22:55:58,393 - DEBUG [main:i.c.c.i.a.r.d.ProgramTwillApplication@127] - Localizing file for program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf: artifacts_archive.jar LocalizeResource{archive=false, uri=file:/tmp/default_xml-to-json-141KB_DataPipelineWorkflow_c6bfd724-c6a8-11ed-8be4-3e40d30925cf/artifacts_archive_e05a6033858b1b079c55b0c5376f924050a2a6810509f537e0c3236936afdf75_1680652800000.jar}
2023-03-19 22:55:58,394 - DEBUG [main:i.c.c.i.a.r.d.ProgramTwillApplication@127] - Localizing file for program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf: spark-defaults.conf LocalizeResource{archive=false, uri=file:/tmp/default_xml-to-json-141KB_DataPipelineWorkflow_c6bfd724-c6a8-11ed-8be4-3e40d30925cf/data/tmp/1679266547507-0/spark-defaults.conf3650972689930275993.tmp}
2023-03-19 22:55:58,396 - DEBUG [main:i.c.c.i.a.r.d.ProgramTwillApplication@127] - Localizing file for program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf: spark.archive-spark3_2.12-3.2.3.zip LocalizeResource{archive=true, uri=hdfs://cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m/framework/spark/spark.archive-spark3_2.12-3.2.3.zip}
2023-03-19 22:55:58,397 - DEBUG [main:i.c.c.i.a.r.d.ProgramTwillApplication@127] - Localizing file for program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf: program_366688bda18303296fc427af534a192eb32fd810718b7d9d11c6eab7ef1ca947_1678579200000.jar LocalizeResource{archive=false, uri=file:/tmp/default_xml-to-json-141KB_DataPipelineWorkflow_c6bfd724-c6a8-11ed-8be4-3e40d30925cf/program_366688bda18303296fc427af534a192eb32fd810718b7d9d11c6eab7ef1ca947_1678579200000.jar}
2023-03-19 22:55:58,399 - DEBUG [main:i.c.c.i.a.r.d.ProgramTwillApplication@127] - Localizing file for program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf: py4j-0.10.9-src.zip LocalizeResource{archive=false, uri=file:/usr/lib/spark/python/lib/py4j-0.10.9-src.zip}
2023-03-19 22:55:58,400 - DEBUG [main:i.c.c.i.a.r.d.ProgramTwillApplication@127] - Localizing file for program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf: artifacts LocalizeResource{archive=true, uri=file:/tmp/default_xml-to-json-141KB_DataPipelineWorkflow_c6bfd724-c6a8-11ed-8be4-3e40d30925cf/artifacts_archive_e05a6033858b1b079c55b0c5376f924050a2a6810509f537e0c3236936afdf75_1680652800000.jar}
2023-03-19 22:55:58,421 - INFO  [main:i.c.c.i.a.r.d.DistributedProgramRunner@591] - Starting Workflow Program 'DataPipelineWorkflow' with Arguments [logical.start.time=1679266370962, system.profile.name=SYSTEM:autoscaling-dataproc], with debugging false
2023-03-19 22:56:08,445 - INFO  [ STARTING:o.a.t.y.YarnTwillController@120] - Application workflow.default.xml-to-json-141KB.DataPipelineWorkflow with id application_1679266451939_0001 submitted
2023-03-19 22:56:20,800 - INFO  [ STARTING:o.a.t.y.YarnTwillController@132] - Yarn application workflow.default.xml-to-json-141KB.DataPipelineWorkflow application_1679266451939_0001 is in state RUNNING
2023-03-19 22:56:20,816 - DEBUG [main:i.c.c.i.a.r.d.DistributedProgramRunner@787] - Cleanup tmp files for program:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow: /tmp/default_xml-to-json-141KB_DataPipelineWorkflow_c6bfd724-c6a8-11ed-8be4-3e40d30925cf/data/tmp/1679266547507-0
2023-03-19 22:56:20,823 - INFO  [main:i.c.c.i.a.r.d.AbstractTwillProgramController@69] - Twill program running: program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf, twill runId: 21770f4c-d8c8-4635-b803-2a72570d1321
2023-03-19 22:56:23,085 - INFO  [ApplicationMasterService:o.a.t.i.a.ApplicationMasterService@734] - Request 1 containers with capability <memory:1024, vCores:1> for runnable DataPipelineWorkflow
2023-03-19 22:56:23,184 - DEBUG [TMSLogPublisher:i.c.c.i.a.r.d.r.RemoteExecutionDiscoveryService@142] - Update discoverable messaging.service with address cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m.us-west1-b.c.smooth-keel-381016.internal/10.138.0.38:46683 and payload https://
2023-03-19 22:56:25,208 - INFO  [ApplicationMasterService:o.a.t.i.a.ApplicationMasterService@756] - Container allocated: Container: [ContainerId: container_1679266451939_0001_01_000002, AllocationRequestId: 0, Version: 0, NodeId: cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-w-0.us-west1-b.c.smooth-keel-381016.internal:8026, NodeHttpAddress: cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-w-0.us-west1-b.c.smooth-keel-381016.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.138.0.39:8026 }, ExecutionType: GUARANTEED, ]
2023-03-19 22:56:25,213 - INFO  [ApplicationMasterService:o.a.t.i.a.ApplicationMasterService@763] - Starting runnable DataPipelineWorkflow in Container: [ContainerId: container_1679266451939_0001_01_000002, AllocationRequestId: 0, Version: 0, NodeId: cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-w-0.us-west1-b.c.smooth-keel-381016.internal:8026, NodeHttpAddress: cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-w-0.us-west1-b.c.smooth-keel-381016.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.138.0.39:8026 }, ExecutionType: GUARANTEED, ]
2023-03-19 22:56:25,760 - INFO  [ApplicationMasterService:o.a.t.i.a.RunnableProcessLauncher@71] - Launching in container container_1679266451939_0001_01_000002 at cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-w-0.us-west1-b.c.smooth-keel-381016.internal:8026, [$JAVA_HOME/bin/java -Djava.io.tmpdir=tmp -Dyarn.container=$YARN_CONTAINER_ID -Dtwill.runnable=$TWILL_APP_NAME.$TWILL_RUNNABLE_NAME -cp launcher.jar:$HADOOP_CONF_DIR -Xmx824m -XX:+UseG1GC -verbose:gc -Xloggc:<LOG_DIR>/gc.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+ExitOnOutOfMemoryError -Dlogback.configurationFile=resources.jar/resources/logback.xml -DCDAP_LOG_DIR=<LOG_DIR> -Dlogback.configurationFile=logback.xml -Dtwill.container.class.loader=io.cdap.cdap.common.app.MainClassLoader org.apache.twill.launcher.TwillLauncher org.apache.twill.internal.container.TwillContainerMain true 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr]
2023-03-19 22:56:26,067 - INFO  [ApplicationMasterService:o.a.t.i.a.ApplicationMasterService@799] - Runnable DataPipelineWorkflow fully provisioned with 1 instances.
2023-03-19 22:56:42,006 - DEBUG [TwillContainerService:i.c.c.i.a.r.m.RuntimeMonitors@119] - Setting runtime service routing base URI to https://r-xml-to-json-smooth-keel-381016-dot-usw1.datafusion.googleusercontent.com/v3Internal/runtime/namespaces/default/apps/xml-to-json-141KB/versions/-SNAPSHOT/workflows/DataPipelineWorkflow/runs/c6bfd724-c6a8-11ed-8be4-3e40d30925cf/services/
2023-03-19 22:56:42,348 - DEBUG [TMSLogPublisher:i.c.c.i.a.r.d.r.RemoteExecutionDiscoveryService@142] - Update discoverable messaging.service with address cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m.us-west1-b.c.smooth-keel-381016.internal/10.138.0.38:46683 and payload https://
2023-03-19 22:56:47,727 - INFO  [TwillContainerService:i.c.c.i.a.r.d.AbstractProgramTwillRunnable@157] - Runnable initialized: DataPipelineWorkflow
2023-03-19 22:56:47,767 - INFO  [TwillContainerService:i.c.c.i.a.r.d.AbstractProgramTwillRunnable@241] - Starting program run program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf
2023-03-19 22:56:51,994 - INFO  [WorkflowDriver:i.c.c.d.SmartWorkflow@448] - Pipeline 'xml-to-json-141KB' is started by user 'yarn' with arguments {logical.start.time=1679266370962, system.profile.name=SYSTEM:autoscaling-dataproc}
2023-03-19 22:56:52,082 - INFO  [WorkflowDriver:i.c.c.d.SmartWorkflow@486] - Pipeline 'xml-to-json-141KB' running
2023-03-19 22:56:52,119 - DEBUG [WorkflowDriver:i.c.c.i.a.r.w.WorkflowProgramController@71] - Workflow service workflow.default.xml-to-json-141KB.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf started
2023-03-19 22:56:52,132 - INFO  [WorkflowDriver:i.c.c.i.a.r.w.WorkflowDriver@627] - Starting workflow execution for 'DataPipelineWorkflow' with Run id 'c6bfd724-c6a8-11ed-8be4-3e40d30925cf'
2023-03-19 22:56:52,195 - DEBUG [action-phase-1-0:i.c.c.a.r.s.SparkProgramRuntimeProvider@169] - using sparkCompat SPARK3_2_12
2023-03-19 22:56:52,411 - DEBUG [action-phase-1-0:i.c.c.a.r.s.SparkPackageUtils@317] - Located Spark library in in spark.archive-spark3_2.12-3.2.3.zip
2023-03-19 22:56:52,547 - DEBUG [action-phase-1-0:i.c.c.c.g.DFSLocationModule@76] - Location namespace is /cdap
2023-03-19 22:56:52,552 - DEBUG [action-phase-1-0:i.c.c.c.g.FileContextProvider@68] - Getting filesystem for user yarn
2023-03-19 22:56:52,559 - DEBUG [action-phase-1-0:i.c.c.c.g.DFSLocationModule@94] - Location cache path is data/location.cache
2023-03-19 22:56:52,628 - INFO  [action-phase-1-0:i.c.c.i.a.r.w.WorkflowDriver@341] - Starting Spark Program 'phase-1' in workflow
2023-03-19 22:56:53,060 - DEBUG [action-phase-1-0:i.c.c.a.r.s.SparkProgramRunner@238] - Starting Spark Job. Context: SparkRuntimeContext{id=program:default.xml-to-json-141KB.-SNAPSHOT.spark.phase-1, runId=56c99ea1-c6a9-11ed-99b5-42010a8a0027}
2023-03-19 22:56:59,721 - DEBUG [SparkRunner-phase-1:i.c.c.i.a.r.d.r.RemoteExecutionDiscoveryService@142] - Update discoverable dataset.service with address dataset.service:0 and payload https://
2023-03-19 22:57:00,360 - WARN  [SparkRunner-phase-1:o.a.h.f.FileSystem@3304] - Cannot load filesystem: java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: Provider org.apache.hadoop.hdfs.web.HftpFileSystem not found
2023-03-19 22:57:00,366 - WARN  [SparkRunner-phase-1:o.a.h.f.FileSystem@3304] - Cannot load filesystem: java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: Provider org.apache.hadoop.hdfs.web.HsftpFileSystem not found
2023-03-19 22:57:03,693 - INFO  [SparkExecutionService STARTING:i.c.h.NettyHttpService@181] - Starting HTTP Service phase-1-spark-exec-service at address cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-w-0.us-west1-b.c.smooth-keel-381016.internal/10.138.0.39:0
2023-03-19 22:57:04,324 - DEBUG [spark-submitter-phase-1-56c99ea1-c6a9-11ed-99b5-42010a8a0027:i.c.c.a.r.s.s.AbstractSparkSubmitter@194] - Calling SparkSubmit for program:default.xml-to-json-141KB.-SNAPSHOT.spark.phase-1 56c99ea1-c6a9-11ed-99b5-42010a8a0027: [--master, yarn, --deploy-mode, cluster, --conf, spark.app.name=phase-1, --conf, spark.yarn.am.memory=640m, --conf, spark.executor.extraClassPath=$PWD/cdap-spark-launcher.jar:$PWD/logback.xml.jar:$PWD/cdap-spark.jar/aopalliance.aopalliance-1.0.jar:$PWD/cdap-spark.jar/ch.qos.logback.logback-classic-1.2.11.jar:$PWD/cdap-spark.jar/ch.qos.logback.logback-core-1.2.11.jar:$PWD/cdap-spark.jar/com.101tec.zkclient-0.3.jar:$PWD/cdap-spark.jar/com.google.code.findbugs.jsr305-2.0.1.jar:$PWD/cdap-spark.jar/com.google.code.gson.gson-2.3.1.jar:$PWD/cdap-spark.jar/com.google.guava.guava-13.0.1.jar:$PWD/cdap-spark.jar/com.google.inject.extensions.guice-assistedinject-4.0.jar:$PWD/cdap-spark.jar/com.google.inject.extensions.guice-multibindings-4.0.jar:$PWD/cdap-spark.jar/com.google.inject.guice-4.0.jar:$PWD/cdap-spark.jar/commons-beanutils.commons-beanutils-1.7.0.jar:$PWD/cdap-spark.jar/commons-compiler-3.0.16.jar:$PWD/cdap-spark.jar/commons-io.commons-io-2.4.jar:$PWD/cdap-spark.jar/error_prone_annotations-2.3.4.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-api-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-api-common-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-api-spark3_2.12-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-app-fabric-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-common-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-data-fabric-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-error-api-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-explore-client-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-formats-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-hbase-compat-base-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-hbase-spi-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-master-spi-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-metadata-spi-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-proto-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-runtime-spi-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-security-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-security-spi-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-spark-core3_2.12-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-spark-python-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-storage-spi-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-system-app-api-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-tms-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-watchdog-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-watchdog-api-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.common.common-http-0.13.1.jar:$PWD/cdap-spark.jar/io.cdap.common.common-io-0.13.1.jar:$PWD/cdap-spark.jar/io.cdap.http.netty-http-1.7.0.jar:$PWD/cdap-spark.jar/io.cdap.twill.twill-api-1.2.0.jar:$PWD/cdap-spark.jar/io.cdap.twill.twill-common-1.2.0.jar:$PWD/cdap-spark.jar/io.cdap.twill.twill-core-1.2.0.jar:$PWD/cdap-spark.jar/io.cdap.twill.twill-discovery-api-1.2.0.jar:$PWD/cdap-spark.jar/io.cdap.twill.twill-discovery-core-1.2.0.jar:$PWD/cdap-spark.jar/io.cdap.twill.twill-yarn-1.2.0.jar:$PWD/cdap-spark.jar/io.cdap.twill.twill-zookeeper-1.2.0.jar:$PWD/cdap-spark.jar/io.dropwizard.metrics.metrics-core-3.1.2.jar:$PWD/cdap-spark.jar/io.netty.netty-all-4.1.16.Final.jar:$PWD/cdap-spark.jar/it.unimi.dsi.fastutil-6.5.6.jar:$PWD/cdap-spark.jar/jackson-core-asl-1.9.13.jar:$PWD/cdap-spark.jar/jackson-mapper-asl-1.9.13.jar:$PWD/cdap-spark.jar/janino-3.0.16.jar:$PWD/cdap-spark.jar/javax.inject.javax.inject-1.jar:$PWD/cdap-spark.jar/javax.ws.rs.javax.ws.rs-api-2.0.jar:$PWD/cdap-spark.jar/log4j.log4j-1.2.16.jar:$PWD/cdap-spark.jar/net.sf.jopt-simple.jopt-simple-3.2.jar:$PWD/cdap-spark.jar/org.apache.avro.avro-1.8.2.jar:$PWD/cdap-spark.jar/org.apache.commons.commons-compress-1.18.jar:$PWD/cdap-spark.jar/org.apache.commons.commons-dbcp2-2.6.0.jar:$PWD/cdap-spark.jar/org.apache.commons.commons-pool2-2.6.1.jar:$PWD/cdap-spark.jar/org.apache.tephra.tephra-api-0.15.0-incubating.jar:$PWD/cdap-spark.jar/org.apache.tephra.tephra-core-0.15.0-incubating.jar:$PWD/cdap-spark.jar/org.apache.thrift.libthrift-0.9.3.jar:$PWD/cdap-spark.jar/org.bouncycastle.bcpkix-jdk15on-1.60.jar:$PWD/cdap-spark.jar/org.bouncycastle.bcprov-jdk15on-1.60.jar:$PWD/cdap-spark.jar/org.iq80.leveldb.leveldb-0.12-uber.jar:$PWD/cdap-spark.jar/org.ow2.asm.asm-7.1.jar:$PWD/cdap-spark.jar/org.ow2.asm.asm-commons-7.1.jar:$PWD/cdap-spark.jar/org.ow2.asm.asm-tree-7.1.jar:$PWD/cdap-spark.jar/org.quartz-scheduler.quartz-2.2.0.jar:$PWD/cdap-spark.jar/org.slf4j.jcl-over-slf4j-1.7.15.jar:$PWD/cdap-spark.jar/org.slf4j.jul-to-slf4j-1.7.15.jar:$PWD/cdap-spark.jar/org.slf4j.slf4j-api-1.7.15.jar:$PWD/cdap-spark.jar/protobuf-java-2.5.0.jar:$PWD/cdap-spark.jar/zookeeper-3.4.6.jar:, --conf, spark.network.timeout=600s, --conf, spark.network.maxRemoteBlockSizeFetchToMem=2147483135, --conf, spark.yarn.jars=local:/usr/lib/spark/jars/*, --conf, spark.sql.adaptive.enabled=true, --conf, spark.sql.cbo.joinReorder.enabled=true, --conf, spark.dynamicAllocation.minExecutors=1, --conf, spark.yarn.historyServer.address=cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m:18080, --conf, spark.task.maxFailures=10, --conf, spark.history.fs.logDirectory=gs://dataproc-temp-us-west1-738979054940-hx2scday/2cd4d382-a52e-49ec-8d5b-89fdd216681c/spark-job-history, --conf, spark.driver.memory=2048m, --conf, spark.driver.cores=1, --conf, spark.yarn.archive=hdfs://cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m/framework/spark/spark.archive-spark3_2.12-3.2.3.zip, --conf, spark.yarn.maxAppAttempts=1, --conf, spark.ui.port=0, --conf, spark.speculation=false, --conf, spark.stage.maxConsecutiveAttempts=10, --conf, spark.app.id=xml-to-json-141KB, --conf, spark.dataproc.metrics.listener.metrics.collector.hostname=cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m, --conf, spark.extraListeners=io.cdap.cdap.app.runtime.spark.DelegatingSparkListener,com.google.cloud.spark.performance.DataprocMetricsListener, --conf, spark.yarn.security.tokens.hbase.enabled=false, --conf, spark.dataproc.sql.optimizer.leftsemijoin.conversion.enabled=true, --conf, spark.executorEnv.CDAP_LOG_DIR=<LOG_DIR>, --conf, spark.dataproc.sql.joinConditionReorder.enabled=true, --conf, spark.yarn.unmanagedAM.enabled=true, --conf, spark.sql.cbo.enabled=true, --conf, spark.cdap.localized.resources=["HydratorSpark.config"], --conf, spark.dynamicAllocation.enabled=true, --conf, spark.driver.extraJavaOptions=-XX:+UseG1GC -verbose:gc -Xloggc:<LOG_DIR>/gc.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+ExitOnOutOfMemoryError -Dstreaming.checkpoint.rewrite.enabled=true, --conf, spark.yarn.executor.failuresValidityInterval=1h, --conf, spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version=2, --conf, spark.driver.maxResultSize=1024m, --conf, spark.sql.catalogImplementation=hive, --conf, spark.driver.extraClassPath=$PWD/cdap-spark-launcher.jar:$PWD/logback.xml.jar:$PWD/cdap-spark.jar/aopalliance.aopalliance-1.0.jar:$PWD/cdap-spark.jar/ch.qos.logback.logback-classic-1.2.11.jar:$PWD/cdap-spark.jar/ch.qos.logback.logback-core-1.2.11.jar:$PWD/cdap-spark.jar/com.101tec.zkclient-0.3.jar:$PWD/cdap-spark.jar/com.google.code.findbugs.jsr305-2.0.1.jar:$PWD/cdap-spark.jar/com.google.code.gson.gson-2.3.1.jar:$PWD/cdap-spark.jar/com.google.guava.guava-13.0.1.jar:$PWD/cdap-spark.jar/com.google.inject.extensions.guice-assistedinject-4.0.jar:$PWD/cdap-spark.jar/com.google.inject.extensions.guice-multibindings-4.0.jar:$PWD/cdap-spark.jar/com.google.inject.guice-4.0.jar:$PWD/cdap-spark.jar/commons-beanutils.commons-beanutils-1.7.0.jar:$PWD/cdap-spark.jar/commons-compiler-3.0.16.jar:$PWD/cdap-spark.jar/commons-io.commons-io-2.4.jar:$PWD/cdap-spark.jar/error_prone_annotations-2.3.4.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-api-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-api-common-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-api-spark3_2.12-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-app-fabric-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-common-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-data-fabric-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-error-api-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-explore-client-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-formats-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-hbase-compat-base-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-hbase-spi-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-master-spi-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-metadata-spi-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-proto-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-runtime-spi-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-security-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-security-spi-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-spark-core3_2.12-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-spark-python-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-storage-spi-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-system-app-api-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-tms-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-watchdog-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.cdap.cdap-watchdog-api-6.8.1.jar:$PWD/cdap-spark.jar/io.cdap.common.common-http-0.13.1.jar:$PWD/cdap-spark.jar/io.cdap.common.common-io-0.13.1.jar:$PWD/cdap-spark.jar/io.cdap.http.netty-http-1.7.0.jar:$PWD/cdap-spark.jar/io.cdap.twill.twill-api-1.2.0.jar:$PWD/cdap-spark.jar/io.cdap.twill.twill-common-1.2.0.jar:$PWD/cdap-spark.jar/io.cdap.twill.twill-core-1.2.0.jar:$PWD/cdap-spark.jar/io.cdap.twill.twill-discovery-api-1.2.0.jar:$PWD/cdap-spark.jar/io.cdap.twill.twill-discovery-core-1.2.0.jar:$PWD/cdap-spark.jar/io.cdap.twill.twill-yarn-1.2.0.jar:$PWD/cdap-spark.jar/io.cdap.twill.twill-zookeeper-1.2.0.jar:$PWD/cdap-spark.jar/io.dropwizard.metrics.metrics-core-3.1.2.jar:$PWD/cdap-spark.jar/io.netty.netty-all-4.1.16.Final.jar:$PWD/cdap-spark.jar/it.unimi.dsi.fastutil-6.5.6.jar:$PWD/cdap-spark.jar/jackson-core-asl-1.9.13.jar:$PWD/cdap-spark.jar/jackson-mapper-asl-1.9.13.jar:$PWD/cdap-spark.jar/janino-3.0.16.jar:$PWD/cdap-spark.jar/javax.inject.javax.inject-1.jar:$PWD/cdap-spark.jar/javax.ws.rs.javax.ws.rs-api-2.0.jar:$PWD/cdap-spark.jar/log4j.log4j-1.2.16.jar:$PWD/cdap-spark.jar/net.sf.jopt-simple.jopt-simple-3.2.jar:$PWD/cdap-spark.jar/org.apache.avro.avro-1.8.2.jar:$PWD/cdap-spark.jar/org.apache.commons.commons-compress-1.18.jar:$PWD/cdap-spark.jar/org.apache.commons.commons-dbcp2-2.6.0.jar:$PWD/cdap-spark.jar/org.apache.commons.commons-pool2-2.6.1.jar:$PWD/cdap-spark.jar/org.apache.tephra.tephra-api-0.15.0-incubating.jar:$PWD/cdap-spark.jar/org.apache.tephra.tephra-core-0.15.0-incubating.jar:$PWD/cdap-spark.jar/org.apache.thrift.libthrift-0.9.3.jar:$PWD/cdap-spark.jar/org.bouncycastle.bcpkix-jdk15on-1.60.jar:$PWD/cdap-spark.jar/org.bouncycastle.bcprov-jdk15on-1.60.jar:$PWD/cdap-spark.jar/org.iq80.leveldb.leveldb-0.12-uber.jar:$PWD/cdap-spark.jar/org.ow2.asm.asm-7.1.jar:$PWD/cdap-spark.jar/org.ow2.asm.asm-commons-7.1.jar:$PWD/cdap-spark.jar/org.ow2.asm.asm-tree-7.1.jar:$PWD/cdap-spark.jar/org.quartz-scheduler.quartz-2.2.0.jar:$PWD/cdap-spark.jar/org.slf4j.jcl-over-slf4j-1.7.15.jar:$PWD/cdap-spark.jar/org.slf4j.jul-to-slf4j-1.7.15.jar:$PWD/cdap-spark.jar/org.slf4j.slf4j-api-1.7.15.jar:$PWD/cdap-spark.jar/protobuf-java-2.5.0.jar:$PWD/cdap-spark.jar/zookeeper-3.4.6.jar:, --conf, spark.metrics.namespace=spark, --conf, spark.dataproc.sql.local.rank.pushdown.enabled=true, --conf, spark.eventLog.dir=gs://dataproc-temp-us-west1-738979054940-hx2scday/2cd4d382-a52e-49ec-8d5b-89fdd216681c/spark-job-history, --conf, spark.yarn.appMasterEnv.CDAP_LOG_DIR=<LOG_DIR>, --conf, spark.dataproc.sql.parquet.enableFooterCache=true, --conf, spark.executor.instances=2, --conf, spark.executor.memory=2048m, --conf, spark.rpc.message.maxSize=512, --conf, spark.yarn.security.tokens.hive.enabled=false, --conf, spark.yarn.am.attemptFailuresValidityInterval=1h, --conf, spark.scheduler.minRegisteredResourcesRatio=0.0, --conf, spark.executor.id=xml-to-json-141KB, --conf, spark.executor.cores=1, --conf, spark.dynamicAllocation.maxExecutors=10000, --conf, spark.executorEnv.OPENBLAS_NUM_THREADS=1, --conf, spark.sql.caseSensitive=true, --conf, spark.hadoop.hive.execution.engine=mr, --conf, spark.sql.autoBroadcastJoinThreshold=-1, --conf, spark.scheduler.mode=FAIR, --conf, spark.eventLog.enabled=true, --conf, spark.shuffle.service.enabled=true, --conf, spark.executor.extraJavaOptions=-XX:+UseG1GC -verbose:gc -Xloggc:<LOG_DIR>/gc.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+ExitOnOutOfMemoryError -Dstreaming.checkpoint.rewrite.enabled=true, --archives, file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1679266451939_0001/container_1679266451939_0001_01_000002/data/tmp/1679266613186-0/program.jar.expanded.zip,file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1679266451939_0001/container_1679266451939_0001_01_000002/artifacts_archive.jar,file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1679266451939_0001/container_1679266451939_0001_01_000002/data/tmp/1679266613186-0/cdap-spark.jar, --files, file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1679266451939_0001/container_1679266451939_0001_01_000002/tmp/HydratorSpark3114232851510847209.config#HydratorSpark.config,file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1679266451939_0001/container_1679266451939_0001_01_000002/data/tmp/1679266613186-0/program.jar,file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1679266451939_0001/container_1679266451939_0001_01_000002/data/tmp/1679266613186-0/cdap-spark-launcher.jar,file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1679266451939_0001/container_1679266451939_0001_01_000002/data/tmp/1679266613186-0/cConf.xml,file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1679266451939_0001/container_1679266451939_0001_01_000002/data/tmp/1679266613186-0/hConf.xml,file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1679266451939_0001/container_1679266451939_0001_01_000002/data/tmp/1679266613186-0/logback.xml.jar, --class, io.cdap.cdap.app.runtime.spark.SparkMainWrapper, /hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1679266451939_0001/container_1679266451939_0001_01_000002/data/tmp/1679266613186-0/cdapSparkJob.jar, --cdap.spark.program=program_run:default.xml-to-json-141KB.-SNAPSHOT.spark.phase-1.56c99ea1-c6a9-11ed-99b5-42010a8a0027, --cdap.user.main.class=io.cdap.cdap.etl.spark.batch.BatchSparkPipelineDriver]
2023-03-19 22:57:05,616 - WARN  [spark-submitter-phase-1-56c99ea1-c6a9-11ed-99b5-42010a8a0027:o.a.s.d.y.c.package@422] - Can not load the default value of `spark.yarn.isHadoopProvided` from `org/apache/spark/deploy/yarn/config.properties` with error, java.lang.NullPointerException. Using `false` as a default value.
2023-03-19 22:57:12,010 - WARN  [spark-submitter-phase-1-56c99ea1-c6a9-11ed-99b5-42010a8a0027:o.a.s.d.s.HadoopDelegationTokenManager@69] - spark.yarn.security.tokens.hbase.enabled is deprecated.  Please use spark.security.credentials.hbase.enabled instead.
2023-03-19 22:57:12,072 - WARN  [spark-submitter-phase-1-56c99ea1-c6a9-11ed-99b5-42010a8a0027:o.a.s.d.s.HadoopDelegationTokenManager@69] - spark.yarn.security.tokens.hive.enabled is deprecated.  Please use spark.security.credentials.hive.enabled instead.
2023-03-19 22:57:36,082 - INFO  [main:i.c.c.a.r.s.d.SparkContainerLauncher@-2] - Launch main class org.apache.spark.deploy.yarn.ApplicationMaster.main([--class, io.cdap.cdap.app.runtime.spark.SparkMainWrapper, --jar, file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1679266451939_0001/container_1679266451939_0001_01_000002/data/tmp/1679266613186-0/cdapSparkJob.jar, --arg, --cdap.spark.program=program_run:default.xml-to-json-141KB.-SNAPSHOT.spark.phase-1.56c99ea1-c6a9-11ed-99b5-42010a8a0027, --arg, --cdap.user.main.class=io.cdap.cdap.etl.spark.batch.BatchSparkPipelineDriver, --properties-file, /hadoop/yarn/nm-local-dir/usercache/yarn/appcache/application_1679266451939_0002/container_1679266451939_0002_01_000001/__spark_conf__/__spark_conf__.properties, --dist-cache-conf, /hadoop/yarn/nm-local-dir/usercache/yarn/appcache/application_1679266451939_0002/container_1679266451939_0002_01_000001/__spark_conf__/__spark_dist_cache__.properties])
2023-03-19 22:57:43,167 - DEBUG [Driver:i.c.c.a.r.s.SparkRuntimeUtils@303] - Spark events log directory for program_run:default.xml-to-json-141KB.-SNAPSHOT.spark.phase-1.56c99ea1-c6a9-11ed-99b5-42010a8a0027 is /hadoop/yarn/nm-local-dir/usercache/yarn/appcache/application_1679266451939_0002/container_1679266451939_0002_01_000001/tmp/spark-events2284062195538185165
2023-03-19 22:57:43,716 - WARN  [Driver:o.a.h.f.FileSystem@3304] - Cannot load filesystem: java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: Provider org.apache.hadoop.hdfs.web.HftpFileSystem not found
2023-03-19 22:57:43,728 - WARN  [Driver:o.a.h.f.FileSystem@3304] - Cannot load filesystem: java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: Provider org.apache.hadoop.hdfs.web.HsftpFileSystem not found
2023-03-19 22:57:44,938 - INFO  [SparkDriverHttpService STARTING:i.c.h.NettyHttpService@181] - Starting HTTP Service phase-1-http-service at address cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-w-1.us-west1-b.c.smooth-keel-381016.internal/10.138.0.40:0
2023-03-19 22:57:45,620 - INFO  [SparkDriverService:i.c.c.a.r.s.d.SparkDriverService@113] - SparkDriverService started.
2023-03-19 22:57:45,638 - INFO  [Driver:i.c.c.a.r.s.SparkMainWrapper$@78] - Launching user spark class class io.cdap.cdap.etl.spark.batch.BatchSparkPipelineDriver
2023-03-19 22:57:47,366 - INFO  [Driver:o.s.j.u.log@169] - Logging initialized @21399ms to org.sparkproject.jetty.util.log.Slf4jLog
2023-03-19 22:57:47,573 - INFO  [Driver:o.s.j.s.Server@375] - jetty-9.4.40.v20210413; built: 2021-04-13T20:42:42.668Z; git: b881a572662e1943a14ae12e7e1207989f218b74; jvm 1.8.0_362-b09
2023-03-19 22:57:47,641 - INFO  [Driver:o.s.j.s.Server@415] - Started @21674ms
2023-03-19 22:57:47,787 - INFO  [Driver:o.s.j.s.AbstractConnector@331] - Started ServerConnector@41fe2eed{HTTP/1.1, (http/1.1)}{0.0.0.0:42575}
2023-03-19 22:57:47,878 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@440bac7{/jobs,null,AVAILABLE,@Spark}
2023-03-19 22:57:47,893 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@24301010{/jobs/json,null,AVAILABLE,@Spark}
2023-03-19 22:57:47,906 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@50e6d740{/jobs/job,null,AVAILABLE,@Spark}
2023-03-19 22:57:47,918 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@38a3e8db{/jobs/job/json,null,AVAILABLE,@Spark}
2023-03-19 22:57:47,934 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@6859cb71{/stages,null,AVAILABLE,@Spark}
2023-03-19 22:57:47,946 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@2219436{/stages/json,null,AVAILABLE,@Spark}
2023-03-19 22:57:47,956 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@39572b62{/stages/stage,null,AVAILABLE,@Spark}
2023-03-19 22:57:47,964 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@5f726196{/stages/stage/json,null,AVAILABLE,@Spark}
2023-03-19 22:57:47,969 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@6406183d{/stages/pool,null,AVAILABLE,@Spark}
2023-03-19 22:57:47,973 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@7aae8b48{/stages/pool/json,null,AVAILABLE,@Spark}
2023-03-19 22:57:47,977 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@1e931f62{/storage,null,AVAILABLE,@Spark}
2023-03-19 22:57:47,983 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@299cc22c{/storage/json,null,AVAILABLE,@Spark}
2023-03-19 22:57:47,991 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@6cc62edb{/storage/rdd,null,AVAILABLE,@Spark}
2023-03-19 22:57:47,996 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@30cdaf8c{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-03-19 22:57:48,000 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@da24833{/environment,null,AVAILABLE,@Spark}
2023-03-19 22:57:48,005 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@5b7cf0fc{/environment/json,null,AVAILABLE,@Spark}
2023-03-19 22:57:48,010 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@29655e04{/executors,null,AVAILABLE,@Spark}
2023-03-19 22:57:48,014 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@37c4517{/executors/json,null,AVAILABLE,@Spark}
2023-03-19 22:57:48,024 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@6ad3ae9d{/executors/threadDump,null,AVAILABLE,@Spark}
2023-03-19 22:57:48,032 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@2fcd5385{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-03-19 22:57:48,066 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@74d0e4a3{/static,null,AVAILABLE,@Spark}
2023-03-19 22:57:48,071 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@25bd0c07{/,null,AVAILABLE,@Spark}
2023-03-19 22:57:48,080 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@2d205f44{/api,null,AVAILABLE,@Spark}
2023-03-19 22:57:48,089 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@1ea481da{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-03-19 22:57:48,093 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@3c124b09{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-03-19 22:57:48,420 - WARN  [Driver:o.a.s.s.FairSchedulableBuilder@69] - Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.
2023-03-19 22:57:48,807 - INFO  [Driver:o.s.j.s.h.ContextHandler@916] - Started o.s.j.s.ServletContextHandler@6753684b{/metrics/json,null,AVAILABLE,@Spark}
2023-03-19 22:57:50,276 - WARN  [dispatcher-event-loop-1:o.a.s.s.c.YarnSchedulerBackend$YarnSchedulerEndpoint@69] - Attempted to request executors before the AM has registered!
2023-03-19 22:57:55,097 - DEBUG [Driver:i.c.c.e.s.b.RDDUtils@82] - Execution plan:
2023-03-19 22:57:55,180 - DEBUG [Driver:i.c.c.i.a.r.d.r.RemoteExecutionDiscoveryService@142] - Update discoverable dataset.service with address dataset.service:0 and payload https://
2023-03-19 22:57:57,035 - DEBUG [Driver:i.c.c.e.s.b.RDDUtils@83] - (1) MapPartitionsRDD[5] at flatMapToPair at BaseRDDCollection.java:237 []
 |  MapPartitionsRDD[4] at Wrangler (Plugin Wrangler of Type transform, ArtifactId{name='wrangler-transform', version=4.8.1, scope='SYSTEM'}) []
 |  MapPartitionsRDD[3] at Wrangler (Plugin Wrangler of Type transform, ArtifactId{name='wrangler-transform', version=4.8.1, scope='SYSTEM'}) []
 |  MapPartitionsRDD[2] at GCSFile (Plugin GCSFile of Type batchsource, ArtifactId{name='google-cloud', version=0.21.1, scope='SYSTEM'}) []
 |  MapPartitionsRDD[1] at GCSFile (Plugin GCSFile of Type batchsource, ArtifactId{name='google-cloud', version=0.21.1, scope='SYSTEM'}) []
 |  DatasetRDD[0] at GCSFile (Plugin GCSFile of Type batchsource, ArtifactId{name='google-cloud', version=0.21.1, scope='SYSTEM'}) []
2023-03-19 22:57:58,435 - DEBUG [spark-listener-group-shared:i.c.c.a.r.s.AbstractSparkExecutionContext@158] - Spark program=program:default.xml-to-json-141KB.-SNAPSHOT.spark.phase-1, runId=56c99ea1-c6a9-11ed-99b5-42010a8a0027, jobId=0 starts with auto-commit=false on transaction Transaction{readPointer: 9223372036854775806, transactionId: 1679266671845000000, writePointer: 1679266671845000000, invalids: [], inProgress: [], firstShortInProgress: 9223372036854775807, type: LONG, checkpointWritePointers: [], visibilityLevel: SNAPSHOT}
2023-03-19 22:57:58,459 - DEBUG [spark-listener-group-shared:i.c.c.a.r.s.SparkTransactionHandler@110] - Spark job started: JobTransaction{jobId=0, stageIds=[0], transaction=Transaction{readPointer: 9223372036854775806, transactionId: 1679266671845000000, writePointer: 1679266671845000000, invalids: [], inProgress: [], firstShortInProgress: 9223372036854775807, type: LONG, checkpointWritePointers: [], visibilityLevel: SNAPSHOT}}
2023-03-19 22:58:05,751 - INFO  [main:i.c.c.a.r.s.d.SparkContainerLauncher@-2] - Launch main class org.apache.spark.executor.YarnCoarseGrainedExecutorBackend.main([--driver-url, spark://CoarseGrainedScheduler@cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-w-1.us-west1-b.c.smooth-keel-381016.internal:37957, --executor-id, 2, --hostname, cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-w-1.us-west1-b.c.smooth-keel-381016.internal, --cores, 1, --app-id, application_1679266451939_0002, --resourceProfileId, 0, --user-class-path, file:/hadoop/yarn/nm-local-dir/usercache/yarn/appcache/application_1679266451939_0002/container_1679266451939_0002_01_000003/__app__.jar])
2023-03-19 22:58:08,716 - INFO  [main:i.c.c.a.r.s.d.SparkContainerLauncher@-2] - Launch main class org.apache.spark.executor.YarnCoarseGrainedExecutorBackend.main([--driver-url, spark://CoarseGrainedScheduler@cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-w-1.us-west1-b.c.smooth-keel-381016.internal:37957, --executor-id, 1, --hostname, cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-w-0.us-west1-b.c.smooth-keel-381016.internal, --cores, 1, --app-id, application_1679266451939_0002, --resourceProfileId, 0, --user-class-path, file:/hadoop/yarn/nm-local-dir/usercache/yarn/appcache/application_1679266451939_0002/container_1679266451939_0002_01_000002/__app__.jar])
2023-03-19 22:58:14,130 - WARN  [Timer-0:o.a.s.s.c.YarnClusterScheduler@69] - Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
2023-03-19 22:58:20,995 - WARN  [Executor task launch worker for task 0.0 in stage 0.0 (TID 0):o.a.h.f.FileSystem@3304] - Cannot load filesystem: java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: Provider org.apache.hadoop.hdfs.web.HftpFileSystem not found
2023-03-19 22:58:21,008 - WARN  [Executor task launch worker for task 0.0 in stage 0.0 (TID 0):o.a.h.f.FileSystem@3304] - Cannot load filesystem: java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: Provider org.apache.hadoop.hdfs.web.HsftpFileSystem not found
2023-03-19 22:59:08,590 - DEBUG [spark-listener-group-shared:i.c.c.a.r.s.SparkTransactionHandler@144] - Spark job ended: JobTransaction{jobId=0, stageIds=[0], transaction=Transaction{readPointer: 9223372036854775806, transactionId: 1679266671845000000, writePointer: 1679266671845000000, invalids: [], inProgress: [], firstShortInProgress: 9223372036854775807, type: LONG, checkpointWritePointers: [], visibilityLevel: SNAPSHOT}}
2023-03-19 22:59:09,714 - INFO  [Driver:i.c.c.a.r.s.SparkMainWrapper$@95] - Spark main returned class io.cdap.cdap.etl.spark.batch.BatchSparkPipelineDriver
2023-03-19 22:59:10,688 - DEBUG [SparkDriverService:i.c.c.a.r.s.d.SparkDriverService@160] - Heartbeat loop completed with state 'COMPLETED' and terminate timestamp 'null'
2023-03-19 22:59:10,691 - INFO  [phase-1-spark-exec-service-executor-59:i.c.c.a.r.s.d.SparkExecutionService@203] - Spark program completed phase-1 56c99ea1-c6a9-11ed-99b5-42010a8a0027
2023-03-19 22:59:10,702 - DEBUG [SparkDriverService:i.c.c.a.r.s.d.SparkDriverService@178] - SparkDriverService completed with program completion state 'COMPLETED'
2023-03-19 22:59:10,819 - INFO  [SparkDriverService:o.s.j.s.AbstractConnector@381] - Stopped Spark@41fe2eed{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-19 22:59:10,918 - DEBUG [main:i.c.c.l.a.LogAppenderInitializer@137] - Stopping log appender TMSLogAppender
2023-03-19 22:59:10,952 - DEBUG [main:i.c.c.l.a.LogAppenderInitializer@137] - Stopping log appender TMSLogAppender
2023-03-19 22:59:11,570 - DEBUG [SparkDriverService:i.c.c.a.r.s.SparkRuntimeEnv$@347] - Shutting down Server and ThreadPool used by Spark org.apache.spark.SparkContext@456cad22
2023-03-19 22:59:11,584 - INFO  [SparkDriverHttpService STOPPING:i.c.h.NettyHttpService@258] - Stopping HTTP Service phase-1-http-service
2023-03-19 22:59:11,628 - DEBUG [SparkDriverService:i.c.c.i.a.r.d.r.RemoteExecutionDiscoveryService@142] - Update discoverable runtime with address r-xml-to-json-smooth-keel-381016-dot-usw1.datafusion.googleusercontent.com/74.125.135.132:443 and payload https://
2023-03-19 22:59:12,209 - DEBUG [SparkDriverService:i.c.c.a.r.s.SparkRuntimeUtils@394] - Uploaded event logs file /hadoop/yarn/nm-local-dir/usercache/yarn/appcache/application_1679266451939_0002/container_1679266451939_0002_01_000001/tmp/spark-events2284062195538185165/1679266663171.lz4 for program run program_run:default.xml-to-json-141KB.-SNAPSHOT.spark.phase-1.56c99ea1-c6a9-11ed-99b5-42010a8a0027
2023-03-19 22:59:12,221 - DEBUG [main:i.c.c.l.a.LogAppenderInitializer@137] - Stopping log appender TMSLogAppender
2023-03-19 22:59:12,810 - DEBUG [spark-submitter-phase-1-56c99ea1-c6a9-11ed-99b5-42010a8a0027:i.c.c.a.r.s.s.AbstractSparkSubmitter@201] - SparkSubmit returned for program:default.xml-to-json-141KB.-SNAPSHOT.spark.phase-1 56c99ea1-c6a9-11ed-99b5-42010a8a0027
2023-03-19 22:59:12,818 - INFO  [SparkExecutionService STOPPING:i.c.c.a.r.s.d.SparkExecutionService@141] - Shutting down SparkExecutionService
2023-03-19 22:59:12,841 - INFO  [SparkExecutionService STOPPING:i.c.c.a.r.s.d.SparkExecutionService@151] - Shutting down HTTP server
2023-03-19 22:59:12,843 - INFO  [SparkExecutionService STOPPING:i.c.h.NettyHttpService@258] - Stopping HTTP Service phase-1-spark-exec-service
2023-03-19 22:59:13,059 - DEBUG [SparkRunner-phase-1:i.c.c.a.r.s.SparkRuntimeService@995] - Running Spark shutdown hook org.apache.spark.util.SparkShutdownHookManager$$anon$2@47ff3a86
2023-03-19 22:59:13,155 - DEBUG [SparkRunner-phase-1:i.c.c.a.r.s.SparkRuntimeService@463] - Spark program completed: SparkRuntimeContext{id=program:default.xml-to-json-141KB.-SNAPSHOT.spark.phase-1, runId=56c99ea1-c6a9-11ed-99b5-42010a8a0027}
2023-03-19 22:59:13,235 - INFO  [action-phase-1-0:i.c.c.i.a.r.w.WorkflowDriver@344] - Spark Program 'phase-1' in workflow completed
2023-03-19 22:59:13,283 - INFO  [WorkflowDriver:i.c.c.i.a.r.w.WorkflowDriver@635] - Workflow 'DataPipelineWorkflow' with run id 'c6bfd724-c6a8-11ed-8be4-3e40d30925cf' completed
2023-03-19 22:59:13,286 - INFO  [WorkflowDriver:i.c.c.d.SmartWorkflow@544] - Pipeline 'xml-to-json-141KB' succeeded.
2023-03-19 22:59:13,317 - DEBUG [WorkflowDriver:i.c.c.e.l.FieldLineageProcessor@148] - Inputs of following operations are neither part of the input schema of a stage nor are generated by any previous operations recorded by that stage: <stage:GCS2_141KB, [operation:Write, field:body]>. 
2023-03-19 22:59:13,662 - DEBUG [WorkflowDriver:i.c.c.i.a.r.w.WorkflowProgramController@77] - Workflow service terminated from RUNNING. Un-registering service workflow.default.xml-to-json-141KB.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf.
2023-03-19 22:59:13,685 - INFO  [TwillContainerService:i.c.c.i.a.r.d.AbstractProgramTwillRunnable@278] - Program run program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf completed. Releasing resources.
2023-03-19 22:59:13,687 - DEBUG [TwillContainerService:i.c.c.l.a.LogAppenderInitializer@137] - Stopping log appender TMSLogAppender
2023-03-19 22:59:14,622 - INFO  [ApplicationMasterService:o.a.t.i.a.ApplicationMasterService@590] - Container container_1679266451939_0001_01_000002 completed with COMPLETE:.
2023-03-19 22:59:14,738 - INFO  [ApplicationMasterService:o.a.t.i.a.RunningContainers@518] - Container container_1679266451939_0001_01_000002 exited normally with state COMPLETE
2023-03-19 22:59:14,741 - INFO  [ApplicationMasterService:o.a.t.i.a.ApplicationMasterService@503] - All containers completed. Shutting down application master.
2023-03-19 22:59:14,749 - INFO  [ApplicationMasterService:o.a.t.i.a.ApplicationMasterService@337] - Stop application master with spec: {"fsUser":"root","twillAppDir":"hdfs://cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m:8020/workflow.default.xml-to-json-141KB.DataPipelineWorkflow/21770f4c-d8c8-4635-b803-2a72570d1321","zkConnectStr":"cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m:41033","twillRunId":"21770f4c-d8c8-4635-b803-2a72570d1321","twillAppName":"workflow.default.xml-to-json-141KB.DataPipelineWorkflow","rmSchedulerAddr":"cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m:8030","twillSpecification":{"name":"workflow.default.xml-to-json-141KB.DataPipelineWorkflow","runnables":{"DataPipelineWorkflow":{"name":"DataPipelineWorkflow","runnable":{"classname":"io.cdap.cdap.internal.app.runtime.distributed.WorkflowTwillRunnable","name":"DataPipelineWorkflow","arguments":{}},"resources":{"cores":1,"memorySize":1024,"instances":1,"uplink":-1,"downlink":-1},"files":[{"name":"hConf.xml","uri":"hdfs://cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m:8020/workflow.default.xml-to-json-141KB.DataPipelineWorkflow/21770f4c-d8c8-4635-b803-2a72570d1321/hConf.xml.13ae8c05-f598-488f-8539-c0cd61d9a21c.xml","lastModified":1679266565347,"size":215706,"archive":false,"pattern":null},{"name":"program_366688bda18303296fc427af534a192eb32fd810718b7d9d11c6eab7ef1ca947_1678579200000.jar","uri":"hdfs://cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m:8020/workflow.default.xml-to-json-141KB.DataPipelineWorkflow/21770f4c-d8c8-4635-b803-2a72570d1321/program_366688bda18303296fc427af534a192eb32fd810718b7d9d11c6eab7ef1ca947_1678579200000.jar.924f936a-131e-4805-9e99-5d7cdfa9ee67.jar","lastModified":1679266566598,"size":10341463,"archive":false,"pattern":null},{"name":"pyspark.zip","uri":"hdfs://cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m:8020/workflow.default.xml-to-json-141KB.DataPipelineWorkflow/21770f4c-d8c8-4635-b803-2a72570d1321/pyspark.zip.50a2c03d-c132-42f2-9ac5-bd61ac2f2bbf.zip","lastModified":1679266565178,"size":887352,"archive":false,"pattern":null},{"name":"artifacts","uri":"hdfs://cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m:8020/workflow.default.xml-to-json-141KB.DataPipelineWorkflow/21770f4c-d8c8-4635-b803-2a72570d1321/artifacts.56e51e7c-0a47-4ea8-a9d6-fb7a94229fd8.jar","lastModified":1679266567634,"size":289737374,"archive":true,"pattern":null},{"name":"spark-defaults.conf","uri":"hdfs://cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m:8020/workflow.default.xml-to-json-141KB.DataPipelineWorkflow/21770f4c-d8c8-4635-b803-2a72570d1321/spark-defaults.conf.1b1ab3f1-ef7c-46fe-88ce-ee3feb1130f7.tmp","lastModified":1679266566517,"size":1987,"archive":false,"pattern":null},{"name":"appSpec.json","uri":"hdfs://cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m:8020/workflow.default.xml-to-json-141KB.DataPipelineWorkflow/21770f4c-d8c8-4635-b803-2a72570d1321/appSpec.json.de41638a-4126-4fa8-8f6a-4a68e41ac99b.json","lastModified":1679266565307,"size":102111,"archive":false,"pattern":null},{"name":"py4j-0.10.9-src.zip","uri":"hdfs://cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m:8020/workflow.default.xml-to-json-141KB.DataPipelineWorkflow/21770f4c-d8c8-4635-b803-2a72570d1321/py4j-0.10.9-src.zip.0b4c4e83-88ad-4675-94cd-8e0740cc478f.zip","lastModified":1679266566625,"size":41587,"archive":false,"pattern":null},{"name":"program.options.json","uri":"hdfs://cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m:8020/workflow.default.xml-to-json-141KB.DataPipelineWorkflow/21770f4c-d8c8-4635-b803-2a72570d1321/program.options.json.a88ab59f-1160-4789-bf46-5f00d9f50f0f.json","lastModified":1679266565385,"size":3078,"archive":false,"pattern":null},{"name":"cConf.xml","uri":"hdfs://cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m:8020/workflow.default.xml-to-json-141KB.DataPipelineWorkflow/21770f4c-d8c8-4635-b803-2a72570d1321/cConf.xml.89dc9bd8-d7d4-4db5-bb14-e5959ae631f1.xml","lastModified":1679266565423,"size":147977,"archive":false,"pattern":null},{"name":"logback.xml","uri":"hdfs://cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m:8020/workflow.default.xml-to-json-141KB.DataPipelineWorkflow/21770f4c-d8c8-4635-b803-2a72570d1321/logback.xml.153784aa-a446-4093-bfae-d9fb43be8490.xml","lastModified":1679266565221,"size":4013,"archive":false,"pattern":null},{"name":"__spark_conf__","uri":"hdfs://cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m:8020/workflow.default.xml-to-json-141KB.DataPipelineWorkflow/21770f4c-d8c8-4635-b803-2a72570d1321/__spark_conf__.cb9c796e-549c-4940-90b8-c6f5cd43e83a.zip","lastModified":1679266565252,"size":32851,"archive":true,"pattern":null},{"name":"artifacts_archive.jar","uri":"hdfs://cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m:8020/workflow.default.xml-to-json-141KB.DataPipelineWorkflow/21770f4c-d8c8-4635-b803-2a72570d1321/artifacts_archive.jar.b58126e0-d429-428d-a024-c4383ed38b9e.jar","lastModified":1679266566492,"size":289737374,"archive":false,"pattern":null},{"name":"spark.archive-spark3_2.12-3.2.3.zip","uri":"hdfs://cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m/framework/spark/spark.archive-spark3_2.12-3.2.3.zip","lastModified":1679266556953,"size":464950128,"archive":true,"pattern":null}]}},"orders":[{"names":["DataPipelineWorkflow"],"type":"STARTED"}],"placementPolicies":[],"handler":{"classname":"io.cdap.cdap.common.twill.TwillAppLifecycleEventHandler","configs":{"abortIfNotFull":"false","abortTime":"120000"}}},"logLevels":{"DataPipelineWorkflow":{}},"maxRetries":{"DataPipelineWorkflow":0},"config":{"twill.yarn.max.app.attempts":"1","twill.log.collection.enabled":"false"},"runnableConfigs":{"DataPipelineWorkflow":{}}}
2023-03-19 22:59:14,790 - INFO  [ApplicationMasterService:o.a.t.i.a.RunningContainers@393] - Stopping all instances of DataPipelineWorkflow
2023-03-19 22:59:14,791 - INFO  [ApplicationMasterService:o.a.t.i.a.RunningContainers@417] - Terminated all instances of DataPipelineWorkflow
2023-03-19 22:59:14,812 - INFO  [ApplicationMasterService:o.a.t.i.a.ApplicationMasterService@461] - Application directory deleted: hdfs://cdap-xml-to-js-c6bfd724-c6a8-11ed-8be4-3e40d30925cf-m:8020/workflow.default.xml-to-json-141KB.DataPipelineWorkflow/21770f4c-d8c8-4635-b803-2a72570d1321
2023-03-19 22:59:14,856 - DEBUG [ApplicationMasterService:i.c.c.l.a.LogAppenderInitializer@137] - Stopping log appender TMSLogAppender
2023-03-19 22:59:16,009 - DEBUG [main:i.c.c.l.a.LogAppenderInitializer@137] - Stopping log appender TMSLogAppender
2023-03-19 22:59:17,216 - DEBUG [provisioning-task-1:i.c.c.i.p.t.ProvisioningTask@126] - Executing DEPROVISION subtask REQUESTING_DELETE for program run program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf.
2023-03-19 22:59:17,324 - DEBUG [provisioning-task-1:i.c.c.i.p.t.ProvisioningTask@130] - Completed DEPROVISION subtask REQUESTING_DELETE for program run program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf.
2023-03-19 22:59:17,341 - WARN  [provisioning-task-1:i.c.c.r.s.p.d.DataprocProvisioner@457] - Received a request to get the polling strategy for unexpected cluster status RUNNING
2023-03-19 22:59:50,443 - DEBUG [provisioning-task-2:i.c.c.i.p.t.ProvisioningTask@126] - Executing DEPROVISION subtask POLLING_DELETE for program run program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf.
2023-03-19 22:59:50,633 - DEBUG [provisioning-task-2:i.c.c.i.p.t.ProvisioningTask@130] - Completed DEPROVISION subtask POLLING_DELETE for program run program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf.
2023-03-19 22:59:50,652 - DEBUG [provisioning-task-2:i.c.c.i.p.t.ProvisioningTask@117] - Completed DEPROVISION task for program run program_run:default.xml-to-json-141KB.-SNAPSHOT.workflow.DataPipelineWorkflow.c6bfd724-c6a8-11ed-8be4-3e40d30925cf.